---
layout: default
---
<p align="justify" style="line-height: 160%;color:black;width:100%;" class="p2">
Nice to meet you üòÉ <br>
I am Linda, a üì∏camera engineer working on sensing systems for ‚úàÔ∏èflying robots and ü§ñhumanoid robots. I've developed camera modules, lenses, depth sensors, illumination LEDs and thermal sensors that enable the entire robotic sensing systems to perceive and interact with the world around them. Before joining the industry, I earned my üë©‚ÄçüéìPhD in <a href="https://eecs.berkeley.edu/">Electrical Engineering and Computer Sciences from UC Berkeley</a>, where I was advised by <a href="https://www.laurawaller.com/">Prof. Laura Waller</a>. <a href="https://search.proquest.com/openview/e9916003fea6976f7d7cf963b34a5bd5/1?pq-origsite=gscholar&cbl=18750&diss=y">My PhD research</a> focused on üî¨computational optics‚Äîa multidisciplinary field combining optical hardware, physical modeling, optimization algorithms, and machine learning.
</p>

<div class="title">
  News
</div>
<hr class="solid">
Coming soon


<div class="title">
  Selected Publications
</div>
<hr class="solid">

<div class="container">
  <div class="image-section">
    <img src="/assets/img/diffuserlearning-480p.gif" alt="Diffuser Learning">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://openreview.net/forum?id=JJwoJOW4PVZ" target="_blank"> Physics-based learning: Algorithms and optics co-design </a> <br>
    </p> 
    <p class="authorlist">Eric Markley*, <b>Fanglin Linda Liu*</b>(equal contribution), Michael Kellman, Nick Antipa, and Laura Waller<br>
    <i>NeurIPS 2021 Workshop on Deep Learning and Inverse Problems</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://youtu.be/MNYIUbEIhEk?t=3932" target="_blank"> [Youtube]</a> 
      <a href="https://openreview.net/pdf?id=JJwoJOW4PVZ" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We use a differentiable forward model of single-shot 3D microscopy, coupled with an invertible and differentiable reconstruction algorithm, to jointly optimize both the diffuser surface shape and the reconstruction parameters for Fourier DiffuserScope.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/Celegans-480p.gif" alt="C. elegans Reconstruction">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-28-20-28969&id=439689" target="_blank"> Fourier DiffuserScope: Single-shot 3D Microscopy with a diffuser </a> <br>
    </p> 
    <p class="authorlist"><b>Fanglin Linda Liu</b>, Grace Kuo, Nick Antipa, Laura Waller<br>
    <i>Optics Express 28, 28969 (2020)</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/embed/Y8SLZr-cwiY?start=0" target="_blank"> [Youtube]</a> 
      <a href="https://opg.optica.org/oe/viewmedia.cfm?uri=oe-28-20-28969&seq=0" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We demonstrate improved resolution over a large volume with Fourier DiffuserScope, which uses a diffuser in the pupil plane to encode 3D information, then computationally reconstructs the volume by solving a sparsity-constrained inverse problem. Our diffuser consists of randomly placed microlenses with varying focal lengths; the random positions provide a larger field-of-view compared to a conventional microlens array, and the diverse focal lengths improve the axial depth range.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/microfluidic_channel_video.gif" alt="microfluid beads">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-28-6-8384&id=428841" target="_blank"> On chip fluorescence microscopy with a random microlens diffuser </a> <br>
    </p> 
    <p class="authorlist">Grace Kuo,<b>Fanglin Linda Liu</b>, Kristina Monakhova, Kyrollos Yanny, Ren Ng, Laura Waller<br>
    <i>Optics Express 28, 8384 (2020)</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/embed/AXQ7DiBAu2I?start=0" target="_blank"> [Youtube]</a> 
      <a href="https://opg.optica.org/oe/viewmedia.cfm?uri=oe-28-6-8384&seq=0" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We present an on-chip, widefield 3D fluorescence microscope, which consists of a diffuser placed a few millimeters away from a traditional image sensor. The diffuser replaces the optics of a microscope, resulting in a compact and easy-to-assemble system with a practical working distance of over 1.5 mm.
    </span>
  </div>
</div>



<div class="title">
  Work
</div>
<hr class="solid">

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/X10Sensor-480p.gif" alt="X10 Sensor">
  </div>
  <div class="text-section">
    <p class="company"> Skydio
    </p>
    <p class="company-project">Project: <a href="https://www.skydio.com/x10" target="_blank">X10 Camera</a>  
     <br>
    </p> 
    <p class="authorlist">Camera Engineer <br>
    2023 May ‚Äì Present <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://youtu.be/X26Z9ubebNk?si=pN9LxIEfjC5eZEEq&t=1079" target="_blank"> [X10 Keynote]</a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100; margin-bottom:0;">
    Skydio X10 is a cutting-edge drone featuring the most advanced cameras, including a 64MP narrow, 50MP wide, 48MP telephoto, 640 thermal cameras. The drone also incorporates visible and IR navigation cameras for seamless operation both day and night. Powered by the most advanced AI, X10 enables autonomous flight and obstable avoidance at any time.
    X10 was unveiled at the company's 2023 keynote, where my contributions to the camera systems were showcased during the opening "<a href="https://youtu.be/YHNitnLC44w?si=14uQkqfndDHhWrWh&t=72" target="_blank">Sensor Package</a>" session for user cameras and "<a href="https://youtu.be/4pTD7_us5zI?si=8Ain3-AfxTd-q4kK&t=11" target="_blank">Night Sense</a>" session for navigation cameras.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/robotsalute.gif" alt="Robot Cafe">
  </div>
  <div class="text-section">
    <p class="company"> Google X, the moonshot factory
    </p>
    <p class="company-project">Project: <a href="https://x.company/projects/everyday-robots/" target="_blank">Everyday Robots </a>  
     <br>
    </p> 
    <p class="authorlist">Hardware Sensing Engineer <br>
    2022 Feb ‚Äì 2023 Apr <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/watch?v=dCPHGwW9SOk" target="_blank"> [News Report]</a> 
      <a href="https://www.wired.com/story/inside-google-mission-to-give-ai-robot-body/" target="_blank"> [Our Story] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100; margin-bottom:0;">
    Everyday Robots is a moonshot project aimed at building a helper humanoid robot with a general-purpose AI brain. Rather than being designed for a specific task, it is intended to be able to learn new skills in everyday environments. The sensing platform includes stereo cameras, structured illumination, ToF sensors, and Lidar. 
    However, in early 2023, the hardware development was discontinued, and the technology was consolidated into DeepMind's robotics team.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/Silica.gif" alt="Project Silica">
  </div>
  <div class="text-section">
    <p class="company"> Microsoft Research
    </p>
    <p class="company-project"><a href="https://www.microsoft.com/en-us/research/project/project-silica/opportunities/" target="_blank">Project Silica</a>  
     <br>
    </p> 
    <p class="authorlist">Optical Engineer, Intern <br>
    2020 Dec ‚Äì 2021 Mar <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/watch?v=V7L_wdEuQXs" target="_blank"> [Research Talk]</a> 
      <a href="https://www.youtube.com/watch?v=-rfEYd4NGQg" target="_blank"> [Lab Tour] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100; margin-bottom:0;">
    Project Silica addresses the urgent need for sustainable, long-term data storage by writing information into quartz glass. Using an ultrafast femtosecond laser to write and a polarization microscope to read, Project Silica offers a durable alternative to traditional magnetic media like hard disk drives and tapes, which degrade within decades. In contrast, quartz glass provides a cost-effective, sustainable solution that lasts for millennia.
    </span>
  </div>
</div>


<div class="title">
  Community Services, Teaching and Mentoring
</div>
<hr class="solid">

<div class="container">
  <div class="image-section">
    <center><img style="margin-top: 20px;width:70%" src="/assets/img/cgpsa.jpeg" alt="CGPSA Logo"></center>
  </div>
  <div class="text-section">
    <p class="company"> Chinese Graduate and Postdoctoral Scholars Association at UC Berkeley (<a href="https://cgpsa.berkeley.edu" target="_blank">CGPSA</a>)
    </p>
    <p class="authorlist">President <br>
    2018 ‚Äì 2019 <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://mp.weixin.qq.com/s/vXJrhuH5zcXqzmqaLF4HlA" target="_blank"> [2019 Chinese New Year]</a> 
      <a href="https://mp.weixin.qq.com/s/7G6LVYDL5VWqT2-4oZDlHg" target="_blank"> [2018 New Student Reception]</a> <br>
      <a href="https://mp.weixin.qq.com/s/aMoLpG_hpU5v2ZrdL6sSKA" target="_blank"> [2018 Fall Hiking] </a> 
      <a href="https://mp.weixin.qq.com/s/iLeoFNW1suosG4GqZziUOQ" target="_blank"> [2019 Spring Hiking] </a> 
    <br>
    </span> 
    <br>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <center><img style="margin-top: 20px;width:70%" src="/assets/img/wicse.png" alt="WICSE Logo"></center>
  </div>
  <div class="text-section">
    <p class="company"> Women in Computer Science and Electrical Engineering (<a href="https://inst.eecs.berkeley.edu/~wicse/" target="_blank">WICSE</a>)
    </p>
    <p class="authorlist">Officer <br>
    2017 - 2018 <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://newsletter.eecs.berkeley.edu/2020/09/wicse-history/" target="_blank"> [WICSE History]</a> 
    <br>
    </span> 
    <br>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <center><img style="margin-top: 0px; width:50%;" src="/assets/img/eecs16a.png" alt="EECS16A Course Logo"></center>
  </div>
  <div class="text-section">
    <p class="company"> <a href="https://eecs16a.org" target="_blank">EECS16A</a>: Designing Informative Devices and Systems 
    </p>
    <p class="authorlist">Spring 2019: Head Content Teaching Assistant <br>
    Fall 2021: Content Teaching Assistant <br> 
    </p>
    <br>
  </div>
</div>

