---
layout: default
---
<p align="justify" style="line-height: 160%;color:black;width:100%;" class="p2">
Nice to meet you üòÉ <br>
I am Linda, a üì∏camera engineer working on sensing systems for ‚úàÔ∏èflying robots and ü§ñhumanoid robots. I've developed camera modules, lenses, depth sensors, illumination LEDs and thermal sensors that enable the entire robotic sensing systems to perceive and interact with the world around them. Before joining the industry, I earned my üë©‚ÄçüéìPhD in Electrical Engineering and Computer Sciences from UC Berkeley, where I was advised by Prof. Laura Waller. My PhD research focused on üî¨computational optics‚Äîa multidisciplinary field combining optical hardware, physical modeling, optimization algorithms, and machine learning.
</p>

<div class="title">
  News
</div>
<hr class="solid">
Coming soon


<div class="title">
  Selected Publications
</div>
<hr class="solid">

<div class="container">
  <div class="image-section">
    <img src="/assets/img/diffuserlearning-480p.gif" alt="Diffuser Learning">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://openreview.net/forum?id=JJwoJOW4PVZ" target="_blank"> Physics-based learning: Algorithms and optics co-design </a> <br>
    </p> 
    <p class="authorlist">Eric Markley*, <b>Fanglin Linda Liu*</b>(equal contribution), Michael Kellman, Nick Antipa, and Laura Waller<br>
    <i>NeurIPS 2021 Workshop on Deep Learning and Inverse Problems</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://youtu.be/MNYIUbEIhEk?t=3932" target="_blank"> [Youtube]</a> 
      <a href="https://openreview.net/pdf?id=JJwoJOW4PVZ" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We use a differentiable forward model of single-shot 3D microscopy, coupled with an invertible and differentiable reconstruction algorithm, to jointly optimize both the diffuser surface shape and the reconstruction parameters for Fourier DiffuserScope.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/Celegans-480p.gif" alt="C. elegans Reconstruction">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-28-20-28969&id=439689" target="_blank"> Fourier DiffuserScope: Single-shot 3D Microscopy with a diffuser </a> <br>
    </p> 
    <p class="authorlist"><b>Fanglin Linda Liu</b>, Grace Kuo, Nick Antipa, Laura Waller<br>
    <i>Optics Express 28, 28969 (2020)</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/embed/Y8SLZr-cwiY?start=0" target="_blank"> [Youtube]</a> 
      <a href="https://opg.optica.org/oe/viewmedia.cfm?uri=oe-28-20-28969&seq=0" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We demonstrate improved resolution over a large volume with Fourier DiffuserScope, which uses a diffuser in the pupil plane to encode 3D information, then computationally reconstructs the volume by solving a sparsity-constrained inverse problem. Our diffuser consists of randomly placed microlenses with varying focal lengths; the random positions provide a larger field-of-view compared to a conventional microlens array, and the diverse focal lengths improve the axial depth range.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/microfluidic_channel_video.gif" alt="microfluid beads">
  </div>
  <div class="text-section">
    <p class="title-paper"><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-28-6-8384&id=428841" target="_blank"> On chip fluorescence microscopy with a random microlens diffuser </a> <br>
    </p> 
    <p class="authorlist">Grace Kuo,<b>Fanglin Linda Liu</b>, Kristina Monakhova, Kyrollos Yanny, Ren Ng, Laura Waller<br>
    <i>Optics Express 28, 8384 (2020)</i> <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/embed/AXQ7DiBAu2I?start=0" target="_blank"> [Youtube]</a> 
      <a href="https://opg.optica.org/oe/viewmedia.cfm?uri=oe-28-6-8384&seq=0" target="_blank"> [pdf] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100;margin-bottom:0;">
    We present an on-chip, widefield 3D fluorescence microscope, which consists of a diffuser placed a few millimeters away from a traditional image sensor. The diffuser replaces the optics of a microscope, resulting in a compact and easy-to-assemble system with a practical working distance of over 1.5 mm.
    </span>
  </div>
</div>



<div class="title">
  Work
</div>
<hr class="solid">

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/robotsalute.gif" alt="microfluid beads">
  </div>
  <div class="text-section">
    <p class="company"> Google X, the moonshot factory
    </p>
    <p class="company-project">Project: <a href="https://x.company/projects/everyday-robots/" target="_blank">Everyday Robots </a>  
     <br>
    </p> 
    <p class="authorlist">Hardware sensing engineer <br>
    2022 Feb ‚Äì 2023 Apr <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/watch?v=dCPHGwW9SOk" target="_blank"> [News Report]</a> 
      <a href="https://www.wired.com/story/inside-google-mission-to-give-ai-robot-body/" target="_blank"> [Our Story] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100; margin-bottom:0;">
    Everyday Robots is a moonshot project aimed at building a helper humanoid robot with a general-purpose AI brain. Rather than being designed for a specific task, it is intended to be able to learn new skills in everyday environments. The sensing platform includes stereo cameras, structured illumination, ToF sensors, and Lidar. 
    However, in early 2023, the hardware development was discontinued, and the technology was consolidated into DeepMind's robotics team.
    </span>
  </div>
</div>

<div class="container">
  <div class="image-section">
    <img style="margin-top: 20px" src="/assets/img/Silica.gif" alt="microfluid beads">
  </div>
  <div class="text-section">
    <p class="company"> Microsoft Research
    </p>
    <p class="company-project"><a href="https://www.microsoft.com/en-us/research/project/project-silica/opportunities/" target="_blank">Project Silica</a>  
     <br>
    </p> 
    <p class="authorlist">Optical Engineer, Intern <br>
    2020 Dec ‚Äì 2021 Mar <br> 
    </p>
    <span style="font-size:13px;color:black;margin-bottom:0;">
      <a href="https://www.youtube.com/watch?v=V7L_wdEuQXs" target="_blank"> [Research Talk]</a> 
      <a href="https://www.youtube.com/watch?v=-rfEYd4NGQg" target="_blank"> [Lab Tour] </a> 
    <br>
    </span> 
    <br>
    <span style="font-size:13px; font-weight: 100; margin-bottom:0;">
    Project Silica addresses the urgent need for sustainable, long-term data storage by writing information into quartz glass. Using an ultrafast femtosecond laser to write and a polarization microscope to read, Project Silica offers a durable alternative to traditional magnetic media like hard disk drives and tapes, which degrade within decades. In contrast, quartz glass provides a cost-effective, sustainable solution that lasts for millennia.
    </span>
  </div>
</div>


<div class="title">
  Community Services, Teaching and Mentoring
</div>
<hr class="solid">
### Chinese Graduate and Postdoctoral Scholars Association at UC Berkeley (<a href="https://cgpsa.berkeley.edu" target="_blank">CGPSA</a>)
<ul><table>
  <tr>
    <td style="width:20%;border:none;"> <img src="/assets/img/cgpsa.jpeg" height="50"  alt="CGPSA Logo"> </td>
    <td style="border:none;">President, 2018 -- 2019</td>
   </tr> 
</table></ul>

### Women in Computer Science and Electrical Engineering (<a href="https://inst.eecs.berkeley.edu/~wicse/" target="_blank">WICSE</a>)
<ul><table>
  <tr>
    <td style="width:20%;border:none;"> <img src="/assets/img/wicse.png" height="30"  alt="WICSE Logo"> </td>
    <td style="border:none;">Officer, 2017 -- 2018</td>
   </tr> 
</table></ul>

### Berkeley <a href="https://eecs16a.org" target="_blank">EECS16A</a>: Designing Informative Devices and Systems 
<ul><table>
  <tr>
    <td style="width:20%;border:none;"><img src="/assets/img/eecs16a.png" height="80"  alt="EECS16A Course Logo"></td>
    <td style="border:none;">Head Content TA, Spring 2019 <BR> Content TA, Fall 2021</td>
   </tr> 
</table></ul>


### Undergraduate Research Mentor
Mentored 5 undergrads through "Research Experiences for Undergraduates" programs.

